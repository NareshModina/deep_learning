{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hk_du9-mh0x4"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "assert sys.version_info >= (3, 7)\n",
    "from packaging import version\n",
    "import tensorflow as tf\n",
    "assert version.parse(tf.__version__) >= version.parse(\"2.8.0\")\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_bq6i8o1jcSt",
    "outputId": "6fcea64e-1958-439b-c37a-aef7329068eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/ageron/data/raw/main/ridership.tgz\n",
      "\u001b[1m108512/108512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.get_file(\n",
    "    \"ridership.tgz\",\n",
    "    \"https://github.com/ageron/data/raw/main/ridership.tgz\",\n",
    "    cache_dir=\".\",\n",
    "    extract=True\n",
    ")\n",
    "path = Path(\"datasets/ridership/CTA_-_Ridership_-_Daily_Boarding_Totals.csv\")\n",
    "df = pd.read_csv(path, parse_dates=[\"service_date\"])\n",
    "df.columns = [\"date\", \"day_type\", \"bus\", \"rail\", \"total\"]  # shorter names\n",
    "df = df.sort_values(\"date\").set_index(\"date\")\n",
    "df = df.drop(\"total\", axis=1)  # no need for total, it's just bus + rail\n",
    "df = df.drop_duplicates()  # remove duplicated months (2011-10 and 2014-07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S-W5HcTXiXXO"
   },
   "outputs": [],
   "source": [
    "def to_windows(dataset, length):\n",
    "    dataset = dataset.window(length, shift=1, drop_remainder=True)\n",
    "    return dataset.flat_map(lambda window_ds: window_ds.batch(length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VOYR91ndjEYD"
   },
   "outputs": [],
   "source": [
    "df_mulvar = df[[\"bus\", \"rail\"]] / 1e6  # use both bus & rail series as input\n",
    "df_mulvar[\"next_day_type\"] = df[\"day_type\"].shift(-1)  # we know tomorrow's type\n",
    "df_mulvar = pd.get_dummies(df_mulvar)  # one-hot encode the day type\n",
    "mulvar_train = df_mulvar[\"2016-01\":\"2018-12\"]\n",
    "mulvar_valid = df_mulvar[\"2019-01\":\"2019-05\"]\n",
    "mulvar_test = df_mulvar[\"2019-06\":]\n",
    "\n",
    "tf.random.set_seed(42)  # extra code – ensures reproducibility\n",
    "seq_length = 56\n",
    "# Convert all columns to numeric type before creating the dataset\n",
    "# Convert all columns to numeric type, ensuring they are standard float types (float32 or float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BDscH2tDiBI4",
    "outputId": "1a17f729-00b5-4b2d-e636-8a01c16880d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(4, 3), dtype=int64, numpy=\n",
       " array([[0, 1, 2],\n",
       "        [1, 2, 3],\n",
       "        [2, 3, 4],\n",
       "        [3, 4, 5]])>,\n",
       " <tf.Tensor: shape=(4, 3), dtype=int64, numpy=\n",
       " array([[1, 2, 3],\n",
       "        [2, 3, 4],\n",
       "        [3, 4, 5],\n",
       "        [4, 5, 6]])>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_series = tf.data.Dataset.range(7)\n",
    "dataset = to_windows(to_windows(my_series, 3), 4)\n",
    "list(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5yfKJkpAiKep",
    "outputId": "c4987d1b-e51b-4932-8582-3b25cf2f1e4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<tf.Tensor: shape=(4,), dtype=int64, numpy=array([0, 1, 2, 3])>,\n",
       "  <tf.Tensor: shape=(4, 2), dtype=int64, numpy=\n",
       "  array([[1, 2],\n",
       "         [2, 3],\n",
       "         [3, 4],\n",
       "         [4, 5]])>),\n",
       " (<tf.Tensor: shape=(4,), dtype=int64, numpy=array([1, 2, 3, 4])>,\n",
       "  <tf.Tensor: shape=(4, 2), dtype=int64, numpy=\n",
       "  array([[2, 3],\n",
       "         [3, 4],\n",
       "         [4, 5],\n",
       "         [5, 6]])>)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.map(lambda S: (S[:, 0], S[:, 1:]))\n",
    "list(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cpnvfuZfihJq"
   },
   "outputs": [],
   "source": [
    "def to_seq2seq_dataset(series, seq_length=56, ahead=14, target_col=1,\n",
    "                       batch_size=32, shuffle=False, seed=None):\n",
    "    # Convert all columns in the series to numeric type before creating the dataset\n",
    "    # Explicitly convert to float32 to ensure compatibility with TensorFlow\n",
    "    series = series.astype(np.float32)  # Convert all columns to float32\n",
    "\n",
    "    ds = to_windows(tf.data.Dataset.from_tensor_slices(series.values), ahead + 1) # Pass values to avoid index issues\n",
    "    ds = to_windows(ds, seq_length).map(lambda S: (S[:, 0], S[:, 1:, 1]))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(8 * batch_size, seed=seed)\n",
    "    return ds.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "id": "uY9iwvFaijMQ",
    "outputId": "f70bf006-df3a-464f-8be8-52b5ff726394"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'to_seq2seq_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a0e82ec0c290>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mseq2seq_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_seq2seq_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulvar_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mseq2seq_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_seq2seq_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulvar_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'to_seq2seq_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "seq2seq_train = to_seq2seq_dataset(mulvar_train, shuffle=True, seed=42)\n",
    "seq2seq_valid = to_seq2seq_dataset(mulvar_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tlzp628blnoF"
   },
   "outputs": [],
   "source": [
    "def fit_and_evaluate(model, train_set, valid_set, learning_rate, epochs=500):\n",
    "    early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_mae\", patience=50, restore_best_weights=True)\n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\n",
    "    model.compile(loss=tf.keras.losses.Huber(), optimizer=opt, metrics=[\"mae\"])\n",
    "    history = model.fit(train_set, validation_data=valid_set, epochs=epochs,\n",
    "                        callbacks=[early_stopping_cb])\n",
    "    valid_loss, valid_mae = model.evaluate(valid_set)\n",
    "    return valid_mae * 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o1PxvuEZkz2G"
   },
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A0ys3C_6imDG",
    "outputId": "5952fe7e-ef17-4357-fbd1-6901c26fb7c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.0862 - mae: 0.3397 - val_loss: 0.0190 - val_mae: 0.1591\n",
      "Epoch 2/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0178 - mae: 0.1646 - val_loss: 0.0176 - val_mae: 0.1433\n",
      "Epoch 3/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0157 - mae: 0.1518 - val_loss: 0.0165 - val_mae: 0.1403\n",
      "Epoch 4/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0149 - mae: 0.1482 - val_loss: 0.0158 - val_mae: 0.1355\n",
      "Epoch 5/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0141 - mae: 0.1430 - val_loss: 0.0151 - val_mae: 0.1321\n",
      "Epoch 6/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0135 - mae: 0.1383 - val_loss: 0.0144 - val_mae: 0.1289\n",
      "Epoch 7/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.0129 - mae: 0.1357 - val_loss: 0.0138 - val_mae: 0.1254\n",
      "Epoch 8/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0124 - mae: 0.1316 - val_loss: 0.0132 - val_mae: 0.1225\n",
      "Epoch 9/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0119 - mae: 0.1279 - val_loss: 0.0128 - val_mae: 0.1193\n",
      "Epoch 10/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0114 - mae: 0.1237 - val_loss: 0.0123 - val_mae: 0.1168\n",
      "Epoch 11/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0109 - mae: 0.1205 - val_loss: 0.0118 - val_mae: 0.1149\n",
      "Epoch 12/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0107 - mae: 0.1187 - val_loss: 0.0115 - val_mae: 0.1125\n",
      "Epoch 13/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0103 - mae: 0.1152 - val_loss: 0.0111 - val_mae: 0.1109\n",
      "Epoch 14/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0100 - mae: 0.1128 - val_loss: 0.0108 - val_mae: 0.1094\n",
      "Epoch 15/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0098 - mae: 0.1116 - val_loss: 0.0106 - val_mae: 0.1081\n",
      "Epoch 16/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0095 - mae: 0.1092 - val_loss: 0.0103 - val_mae: 0.1069\n",
      "Epoch 17/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0094 - mae: 0.1079 - val_loss: 0.0101 - val_mae: 0.1060\n",
      "Epoch 18/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0092 - mae: 0.1068 - val_loss: 0.0100 - val_mae: 0.1052\n",
      "Epoch 19/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0090 - mae: 0.1048 - val_loss: 0.0097 - val_mae: 0.1040\n",
      "Epoch 20/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0090 - mae: 0.1052 - val_loss: 0.0097 - val_mae: 0.1038\n",
      "Epoch 21/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0088 - mae: 0.1035 - val_loss: 0.0095 - val_mae: 0.1031\n",
      "Epoch 22/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0088 - mae: 0.1032 - val_loss: 0.0095 - val_mae: 0.1028\n",
      "Epoch 23/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0087 - mae: 0.1023 - val_loss: 0.0094 - val_mae: 0.1020\n",
      "Epoch 24/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.0085 - mae: 0.1010 - val_loss: 0.0092 - val_mae: 0.1011\n",
      "Epoch 25/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.0085 - mae: 0.1007 - val_loss: 0.0092 - val_mae: 0.1011\n",
      "Epoch 26/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0085 - mae: 0.1005 - val_loss: 0.0091 - val_mae: 0.1005\n",
      "Epoch 27/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0083 - mae: 0.0995 - val_loss: 0.0090 - val_mae: 0.0999\n",
      "Epoch 28/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0083 - mae: 0.0992 - val_loss: 0.0090 - val_mae: 0.0998\n",
      "Epoch 29/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0082 - mae: 0.0986 - val_loss: 0.0089 - val_mae: 0.0996\n",
      "Epoch 30/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0080 - mae: 0.0971 - val_loss: 0.0089 - val_mae: 0.0991\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0098 - mae: 0.1031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "99118.04646253586"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)  # extra code – ensures reproducibility\n",
    "lstm_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(32, return_sequences=True, input_shape=[None, 5]),\n",
    "    tf.keras.layers.Dense(14)\n",
    "])\n",
    "fit_and_evaluate(lstm_model, seq2seq_train, seq2seq_valid,\n",
    "                 learning_rate=0.1, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GtKbK9BQk1jn"
   },
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eAzy-5JDkthO",
    "outputId": "4697ced2-ce97-45d7-bcc0-369c1349cee5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - loss: 0.1367 - mae: 0.4191 - val_loss: 0.0184 - val_mae: 0.1648\n",
      "Epoch 2/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0172 - mae: 0.1515 - val_loss: 0.0161 - val_mae: 0.1358\n",
      "Epoch 3/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.0137 - mae: 0.1368 - val_loss: 0.0145 - val_mae: 0.1278\n",
      "Epoch 4/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0123 - mae: 0.1292 - val_loss: 0.0133 - val_mae: 0.1214\n",
      "Epoch 5/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0113 - mae: 0.1215 - val_loss: 0.0124 - val_mae: 0.1168\n",
      "Epoch 6/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0106 - mae: 0.1158 - val_loss: 0.0116 - val_mae: 0.1137\n",
      "Epoch 7/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.0102 - mae: 0.1127 - val_loss: 0.0112 - val_mae: 0.1116\n",
      "Epoch 8/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.0097 - mae: 0.1097 - val_loss: 0.0107 - val_mae: 0.1099\n",
      "Epoch 9/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0095 - mae: 0.1080 - val_loss: 0.0105 - val_mae: 0.1086\n",
      "Epoch 10/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0093 - mae: 0.1063 - val_loss: 0.0103 - val_mae: 0.1072\n",
      "Epoch 11/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0092 - mae: 0.1055 - val_loss: 0.0102 - val_mae: 0.1067\n",
      "Epoch 12/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0090 - mae: 0.1040 - val_loss: 0.0102 - val_mae: 0.1064\n",
      "Epoch 13/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0087 - mae: 0.1019 - val_loss: 0.0098 - val_mae: 0.1042\n",
      "Epoch 14/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - loss: 0.0087 - mae: 0.1016 - val_loss: 0.0096 - val_mae: 0.1033\n",
      "Epoch 15/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0086 - mae: 0.1006 - val_loss: 0.0097 - val_mae: 0.1029\n",
      "Epoch 16/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0084 - mae: 0.0995 - val_loss: 0.0096 - val_mae: 0.1023\n",
      "Epoch 17/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0084 - mae: 0.0990 - val_loss: 0.0093 - val_mae: 0.1005\n",
      "Epoch 18/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0082 - mae: 0.0979 - val_loss: 0.0091 - val_mae: 0.0995\n",
      "Epoch 19/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0082 - mae: 0.0973 - val_loss: 0.0090 - val_mae: 0.0988\n",
      "Epoch 20/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - loss: 0.0081 - mae: 0.0966 - val_loss: 0.0089 - val_mae: 0.0981\n",
      "Epoch 21/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0080 - mae: 0.0957 - val_loss: 0.0088 - val_mae: 0.0974\n",
      "Epoch 22/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0079 - mae: 0.0950 - val_loss: 0.0087 - val_mae: 0.0965\n",
      "Epoch 23/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0078 - mae: 0.0945 - val_loss: 0.0087 - val_mae: 0.0962\n",
      "Epoch 24/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0077 - mae: 0.0934 - val_loss: 0.0085 - val_mae: 0.0955\n",
      "Epoch 25/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0077 - mae: 0.0931 - val_loss: 0.0085 - val_mae: 0.0948\n",
      "Epoch 26/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0075 - mae: 0.0917 - val_loss: 0.0083 - val_mae: 0.0936\n",
      "Epoch 27/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 0.0074 - mae: 0.0912 - val_loss: 0.0083 - val_mae: 0.0933\n",
      "Epoch 28/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0073 - mae: 0.0901 - val_loss: 0.0082 - val_mae: 0.0926\n",
      "Epoch 29/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.0072 - mae: 0.0896 - val_loss: 0.0081 - val_mae: 0.0919\n",
      "Epoch 30/30\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 0.0071 - mae: 0.0884 - val_loss: 0.0079 - val_mae: 0.0908\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0089 - mae: 0.0950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "90826.6231417656"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)  # extra code – ensures reproducibility\n",
    "gru_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.GRU(32, return_sequences=True, input_shape=[None, 5]),\n",
    "    tf.keras.layers.Dense(14)\n",
    "])\n",
    "fit_and_evaluate(gru_model, seq2seq_train, seq2seq_valid,\n",
    "                 learning_rate=0.1, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bYEVQ-qUkywg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
